{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Fitting and Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from m3util.viz.printing import printer\n",
    "from m3util.ml.optimizers.TrustRegion import TRCG\n",
    "from m3util.viz.style import set_style\n",
    "from m3util.ml.rand import set_seeds\n",
    "from belearn.dataset.dataset import BE_Dataset\n",
    "from belearn.functions.sho import SHO_nn\n",
    "from belearn.nn.nn import batch_training\n",
    "from datetime import datetime\n",
    "\n",
    "from autophyslearn.postprocessing.complex import ComplexPostProcessor\n",
    "from autophyslearn.spectroscopic.nn import Multiscale1DFitter, Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing set for seaborn\n",
      "Pytorch seed was set to 42\n",
      "Numpy seed was set to 42\n",
      "tensorflow seed was set to 42\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "# Specify the filename and the path to save the file\n",
    "filename = \"data_raw.h5\"\n",
    "save_path = \"./Data\"\n",
    "\n",
    "\n",
    "optimizer_TR = {\"name\": \"TRCG\", \"optimizer\": TRCG, \"radius\": 5, \"device\": \"cuda\", \"ADAM_epochs\": 2}\n",
    "# optimizers = [ 'Adam', optimizer_TR]\n",
    "optimizers = [optimizer_TR]\n",
    "noise_list = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "batch_size = [500, 1000, 5000, 10000]\n",
    "epochs = [5]\n",
    "seed = [41, 43, 44, 45, 46]\n",
    "early_stopping_time = 60*3\n",
    "basepath_postfix = 'nn_benchmarks_noise'\n",
    "\n",
    "# Original filename\n",
    "csv_name = 'nn_benchmarks_noise.csv'\n",
    "\n",
    "printing = printer(basepath='./Figures/')\n",
    "\n",
    "set_style(\"printing\")\n",
    "set_seeds(seed=42)\n",
    "\n",
    "data_path = save_path + \"/\" + filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      "├ Measurement_000\n",
      "  ---------------\n",
      "  ├ Channel_000\n",
      "    -----------\n",
      "    ├ Bin_FFT\n",
      "    ├ Bin_Frequencies\n",
      "    ├ Bin_Indices\n",
      "    ├ Bin_Step\n",
      "    ├ Bin_Wfm_Type\n",
      "    ├ Excitation_Waveform\n",
      "    ├ Noise_Floor\n",
      "    ├ Noisy_Data_1\n",
      "    ├ Noisy_Data_2\n",
      "    ├ Noisy_Data_3\n",
      "    ├ Noisy_Data_4\n",
      "    ├ Noisy_Data_5\n",
      "    ├ Noisy_Data_6\n",
      "    ├ Noisy_Data_7\n",
      "    ├ Noisy_Data_8\n",
      "    ├ Position_Indices\n",
      "    ├ Position_Values\n",
      "    ├ Raw_Data\n",
      "    ├ Spatially_Averaged_Plot_Group_000\n",
      "      ---------------------------------\n",
      "      ├ Bin_Frequencies\n",
      "      ├ Max_Response\n",
      "      ├ Mean_Spectrogram\n",
      "      ├ Min_Response\n",
      "      ├ Spectroscopic_Parameter\n",
      "      ├ Step_Averaged_Response\n",
      "    ├ Spatially_Averaged_Plot_Group_001\n",
      "      ---------------------------------\n",
      "      ├ Bin_Frequencies\n",
      "      ├ Max_Response\n",
      "      ├ Mean_Spectrogram\n",
      "      ├ Min_Response\n",
      "      ├ Spectroscopic_Parameter\n",
      "      ├ Step_Averaged_Response\n",
      "    ├ Spectroscopic_Indices\n",
      "    ├ Spectroscopic_Values\n",
      "    ├ UDVS\n",
      "    ├ UDVS_Indices\n",
      "├ Noisy_Data_1_SHO_Fit\n",
      "  --------------------\n",
      "  ├ Noisy_Data_1-SHO_Fit_000\n",
      "    ------------------------\n",
      "    ├ Fit\n",
      "    ├ Guess\n",
      "    ├ Spectroscopic_Indices\n",
      "    ├ Spectroscopic_Values\n",
      "    ├ completed_fit_positions\n",
      "    ├ completed_guess_positions\n",
      "├ Noisy_Data_2_SHO_Fit\n",
      "  --------------------\n",
      "  ├ Noisy_Data_2-SHO_Fit_000\n",
      "    ------------------------\n",
      "    ├ Fit\n",
      "    ├ Guess\n",
      "    ├ Spectroscopic_Indices\n",
      "    ├ Spectroscopic_Values\n",
      "    ├ completed_fit_positions\n",
      "    ├ completed_guess_positions\n",
      "├ Noisy_Data_3_SHO_Fit\n",
      "  --------------------\n",
      "  ├ Noisy_Data_3-SHO_Fit_000\n",
      "    ------------------------\n",
      "    ├ Fit\n",
      "    ├ Guess\n",
      "    ├ Spectroscopic_Indices\n",
      "    ├ Spectroscopic_Values\n",
      "    ├ completed_fit_positions\n",
      "    ├ completed_guess_positions\n",
      "├ Noisy_Data_4_SHO_Fit\n",
      "  --------------------\n",
      "  ├ Noisy_Data_4-SHO_Fit_000\n",
      "    ------------------------\n",
      "    ├ Fit\n",
      "    ├ Guess\n",
      "    ├ Spectroscopic_Indices\n",
      "    ├ Spectroscopic_Values\n",
      "    ├ completed_fit_positions\n",
      "    ├ completed_guess_positions\n",
      "├ Noisy_Data_5_SHO_Fit\n",
      "  --------------------\n",
      "  ├ Noisy_Data_5-SHO_Fit_000\n",
      "    ------------------------\n",
      "    ├ Fit\n",
      "    ├ Guess\n",
      "    ├ Spectroscopic_Indices\n",
      "    ├ Spectroscopic_Values\n",
      "    ├ completed_fit_positions\n",
      "    ├ completed_guess_positions\n",
      "├ Noisy_Data_6_SHO_Fit\n",
      "  --------------------\n",
      "  ├ Noisy_Data_6-SHO_Fit_000\n",
      "    ------------------------\n",
      "    ├ Fit\n",
      "    ├ Guess\n",
      "    ├ Spectroscopic_Indices\n",
      "    ├ Spectroscopic_Values\n",
      "    ├ completed_fit_positions\n",
      "    ├ completed_guess_positions\n",
      "├ Noisy_Data_7_SHO_Fit\n",
      "  --------------------\n",
      "  ├ Noisy_Data_7-SHO_Fit_000\n",
      "    ------------------------\n",
      "    ├ Fit\n",
      "    ├ Guess\n",
      "    ├ Spectroscopic_Indices\n",
      "    ├ Spectroscopic_Values\n",
      "    ├ completed_fit_positions\n",
      "    ├ completed_guess_positions\n",
      "├ Noisy_Data_8_SHO_Fit\n",
      "  --------------------\n",
      "  ├ Noisy_Data_8-SHO_Fit_000\n",
      "    ------------------------\n",
      "    ├ Fit\n",
      "    ├ Guess\n",
      "    ├ Spectroscopic_Indices\n",
      "    ├ Spectroscopic_Values\n",
      "    ├ completed_fit_positions\n",
      "    ├ completed_guess_positions\n",
      "├ Raw_Data_SHO_Fit\n",
      "  ----------------\n",
      "  ├ Raw_Data-SHO_Fit_000\n",
      "    --------------------\n",
      "    ├ Fit\n",
      "    ├ Guess\n",
      "    ├ Spectroscopic_Indices\n",
      "    ├ Spectroscopic_Values\n",
      "    ├ completed_fit_positions\n",
      "    ├ completed_guess_positions\n",
      "Datasets and datagroups within the file:\n",
      "------------------------------------\n",
      "/\n",
      "/Measurement_000\n",
      "/Measurement_000/Channel_000\n",
      "/Measurement_000/Channel_000/Bin_FFT\n",
      "/Measurement_000/Channel_000/Bin_Frequencies\n",
      "/Measurement_000/Channel_000/Bin_Indices\n",
      "/Measurement_000/Channel_000/Bin_Step\n",
      "/Measurement_000/Channel_000/Bin_Wfm_Type\n",
      "/Measurement_000/Channel_000/Excitation_Waveform\n",
      "/Measurement_000/Channel_000/Noise_Floor\n",
      "/Measurement_000/Channel_000/Noisy_Data_1\n",
      "/Measurement_000/Channel_000/Noisy_Data_2\n",
      "/Measurement_000/Channel_000/Noisy_Data_3\n",
      "/Measurement_000/Channel_000/Noisy_Data_4\n",
      "/Measurement_000/Channel_000/Noisy_Data_5\n",
      "/Measurement_000/Channel_000/Noisy_Data_6\n",
      "/Measurement_000/Channel_000/Noisy_Data_7\n",
      "/Measurement_000/Channel_000/Noisy_Data_8\n",
      "/Measurement_000/Channel_000/Position_Indices\n",
      "/Measurement_000/Channel_000/Position_Values\n",
      "/Measurement_000/Channel_000/Raw_Data\n",
      "/Measurement_000/Channel_000/Spatially_Averaged_Plot_Group_000\n",
      "/Measurement_000/Channel_000/Spatially_Averaged_Plot_Group_000/Bin_Frequencies\n",
      "/Measurement_000/Channel_000/Spatially_Averaged_Plot_Group_000/Max_Response\n",
      "/Measurement_000/Channel_000/Spatially_Averaged_Plot_Group_000/Mean_Spectrogram\n",
      "/Measurement_000/Channel_000/Spatially_Averaged_Plot_Group_000/Min_Response\n",
      "/Measurement_000/Channel_000/Spatially_Averaged_Plot_Group_000/Spectroscopic_Parameter\n",
      "/Measurement_000/Channel_000/Spatially_Averaged_Plot_Group_000/Step_Averaged_Response\n",
      "/Measurement_000/Channel_000/Spatially_Averaged_Plot_Group_001\n",
      "/Measurement_000/Channel_000/Spatially_Averaged_Plot_Group_001/Bin_Frequencies\n",
      "/Measurement_000/Channel_000/Spatially_Averaged_Plot_Group_001/Max_Response\n",
      "/Measurement_000/Channel_000/Spatially_Averaged_Plot_Group_001/Mean_Spectrogram\n",
      "/Measurement_000/Channel_000/Spatially_Averaged_Plot_Group_001/Min_Response\n",
      "/Measurement_000/Channel_000/Spatially_Averaged_Plot_Group_001/Spectroscopic_Parameter\n",
      "/Measurement_000/Channel_000/Spatially_Averaged_Plot_Group_001/Step_Averaged_Response\n",
      "/Measurement_000/Channel_000/Spectroscopic_Indices\n",
      "/Measurement_000/Channel_000/Spectroscopic_Values\n",
      "/Measurement_000/Channel_000/UDVS\n",
      "/Measurement_000/Channel_000/UDVS_Indices\n",
      "/Noisy_Data_1_SHO_Fit\n",
      "/Noisy_Data_1_SHO_Fit/Noisy_Data_1-SHO_Fit_000\n",
      "/Noisy_Data_1_SHO_Fit/Noisy_Data_1-SHO_Fit_000/Fit\n",
      "/Noisy_Data_1_SHO_Fit/Noisy_Data_1-SHO_Fit_000/Guess\n",
      "/Noisy_Data_1_SHO_Fit/Noisy_Data_1-SHO_Fit_000/Spectroscopic_Indices\n",
      "/Noisy_Data_1_SHO_Fit/Noisy_Data_1-SHO_Fit_000/Spectroscopic_Values\n",
      "/Noisy_Data_1_SHO_Fit/Noisy_Data_1-SHO_Fit_000/completed_fit_positions\n",
      "/Noisy_Data_1_SHO_Fit/Noisy_Data_1-SHO_Fit_000/completed_guess_positions\n",
      "/Noisy_Data_2_SHO_Fit\n",
      "/Noisy_Data_2_SHO_Fit/Noisy_Data_2-SHO_Fit_000\n",
      "/Noisy_Data_2_SHO_Fit/Noisy_Data_2-SHO_Fit_000/Fit\n",
      "/Noisy_Data_2_SHO_Fit/Noisy_Data_2-SHO_Fit_000/Guess\n",
      "/Noisy_Data_2_SHO_Fit/Noisy_Data_2-SHO_Fit_000/Spectroscopic_Indices\n",
      "/Noisy_Data_2_SHO_Fit/Noisy_Data_2-SHO_Fit_000/Spectroscopic_Values\n",
      "/Noisy_Data_2_SHO_Fit/Noisy_Data_2-SHO_Fit_000/completed_fit_positions\n",
      "/Noisy_Data_2_SHO_Fit/Noisy_Data_2-SHO_Fit_000/completed_guess_positions\n",
      "/Noisy_Data_3_SHO_Fit\n",
      "/Noisy_Data_3_SHO_Fit/Noisy_Data_3-SHO_Fit_000\n",
      "/Noisy_Data_3_SHO_Fit/Noisy_Data_3-SHO_Fit_000/Fit\n",
      "/Noisy_Data_3_SHO_Fit/Noisy_Data_3-SHO_Fit_000/Guess\n",
      "/Noisy_Data_3_SHO_Fit/Noisy_Data_3-SHO_Fit_000/Spectroscopic_Indices\n",
      "/Noisy_Data_3_SHO_Fit/Noisy_Data_3-SHO_Fit_000/Spectroscopic_Values\n",
      "/Noisy_Data_3_SHO_Fit/Noisy_Data_3-SHO_Fit_000/completed_fit_positions\n",
      "/Noisy_Data_3_SHO_Fit/Noisy_Data_3-SHO_Fit_000/completed_guess_positions\n",
      "/Noisy_Data_4_SHO_Fit\n",
      "/Noisy_Data_4_SHO_Fit/Noisy_Data_4-SHO_Fit_000\n",
      "/Noisy_Data_4_SHO_Fit/Noisy_Data_4-SHO_Fit_000/Fit\n",
      "/Noisy_Data_4_SHO_Fit/Noisy_Data_4-SHO_Fit_000/Guess\n",
      "/Noisy_Data_4_SHO_Fit/Noisy_Data_4-SHO_Fit_000/Spectroscopic_Indices\n",
      "/Noisy_Data_4_SHO_Fit/Noisy_Data_4-SHO_Fit_000/Spectroscopic_Values\n",
      "/Noisy_Data_4_SHO_Fit/Noisy_Data_4-SHO_Fit_000/completed_fit_positions\n",
      "/Noisy_Data_4_SHO_Fit/Noisy_Data_4-SHO_Fit_000/completed_guess_positions\n",
      "/Noisy_Data_5_SHO_Fit\n",
      "/Noisy_Data_5_SHO_Fit/Noisy_Data_5-SHO_Fit_000\n",
      "/Noisy_Data_5_SHO_Fit/Noisy_Data_5-SHO_Fit_000/Fit\n",
      "/Noisy_Data_5_SHO_Fit/Noisy_Data_5-SHO_Fit_000/Guess\n",
      "/Noisy_Data_5_SHO_Fit/Noisy_Data_5-SHO_Fit_000/Spectroscopic_Indices\n",
      "/Noisy_Data_5_SHO_Fit/Noisy_Data_5-SHO_Fit_000/Spectroscopic_Values\n",
      "/Noisy_Data_5_SHO_Fit/Noisy_Data_5-SHO_Fit_000/completed_fit_positions\n",
      "/Noisy_Data_5_SHO_Fit/Noisy_Data_5-SHO_Fit_000/completed_guess_positions\n",
      "/Noisy_Data_6_SHO_Fit\n",
      "/Noisy_Data_6_SHO_Fit/Noisy_Data_6-SHO_Fit_000\n",
      "/Noisy_Data_6_SHO_Fit/Noisy_Data_6-SHO_Fit_000/Fit\n",
      "/Noisy_Data_6_SHO_Fit/Noisy_Data_6-SHO_Fit_000/Guess\n",
      "/Noisy_Data_6_SHO_Fit/Noisy_Data_6-SHO_Fit_000/Spectroscopic_Indices\n",
      "/Noisy_Data_6_SHO_Fit/Noisy_Data_6-SHO_Fit_000/Spectroscopic_Values\n",
      "/Noisy_Data_6_SHO_Fit/Noisy_Data_6-SHO_Fit_000/completed_fit_positions\n",
      "/Noisy_Data_6_SHO_Fit/Noisy_Data_6-SHO_Fit_000/completed_guess_positions\n",
      "/Noisy_Data_7_SHO_Fit\n",
      "/Noisy_Data_7_SHO_Fit/Noisy_Data_7-SHO_Fit_000\n",
      "/Noisy_Data_7_SHO_Fit/Noisy_Data_7-SHO_Fit_000/Fit\n",
      "/Noisy_Data_7_SHO_Fit/Noisy_Data_7-SHO_Fit_000/Guess\n",
      "/Noisy_Data_7_SHO_Fit/Noisy_Data_7-SHO_Fit_000/Spectroscopic_Indices\n",
      "/Noisy_Data_7_SHO_Fit/Noisy_Data_7-SHO_Fit_000/Spectroscopic_Values\n",
      "/Noisy_Data_7_SHO_Fit/Noisy_Data_7-SHO_Fit_000/completed_fit_positions\n",
      "/Noisy_Data_7_SHO_Fit/Noisy_Data_7-SHO_Fit_000/completed_guess_positions\n",
      "/Noisy_Data_8_SHO_Fit\n",
      "/Noisy_Data_8_SHO_Fit/Noisy_Data_8-SHO_Fit_000\n",
      "/Noisy_Data_8_SHO_Fit/Noisy_Data_8-SHO_Fit_000/Fit\n",
      "/Noisy_Data_8_SHO_Fit/Noisy_Data_8-SHO_Fit_000/Guess\n",
      "/Noisy_Data_8_SHO_Fit/Noisy_Data_8-SHO_Fit_000/Spectroscopic_Indices\n",
      "/Noisy_Data_8_SHO_Fit/Noisy_Data_8-SHO_Fit_000/Spectroscopic_Values\n",
      "/Noisy_Data_8_SHO_Fit/Noisy_Data_8-SHO_Fit_000/completed_fit_positions\n",
      "/Noisy_Data_8_SHO_Fit/Noisy_Data_8-SHO_Fit_000/completed_guess_positions\n",
      "/Raw_Data_SHO_Fit\n",
      "/Raw_Data_SHO_Fit/Raw_Data-SHO_Fit_000\n",
      "/Raw_Data_SHO_Fit/Raw_Data-SHO_Fit_000/Fit\n",
      "/Raw_Data_SHO_Fit/Raw_Data-SHO_Fit_000/Guess\n",
      "/Raw_Data_SHO_Fit/Raw_Data-SHO_Fit_000/Spectroscopic_Indices\n",
      "/Raw_Data_SHO_Fit/Raw_Data-SHO_Fit_000/Spectroscopic_Values\n",
      "/Raw_Data_SHO_Fit/Raw_Data-SHO_Fit_000/completed_fit_positions\n",
      "/Raw_Data_SHO_Fit/Raw_Data-SHO_Fit_000/completed_guess_positions\n",
      "\n",
      "The main dataset:\n",
      "------------------------------------\n",
      "<HDF5 file \"data_raw.h5\" (mode r+)>\n",
      "\n",
      "The ancillary datasets:\n",
      "------------------------------------\n",
      "<HDF5 dataset \"Position_Indices\": shape (3600, 2), type \"<u4\">\n",
      "<HDF5 dataset \"Position_Values\": shape (3600, 2), type \"<f4\">\n",
      "<HDF5 dataset \"Spectroscopic_Indices\": shape (4, 63360), type \"<u4\">\n",
      "<HDF5 dataset \"Spectroscopic_Values\": shape (4, 63360), type \"<f4\">\n",
      "\n",
      "Metadata or attributes in a datagroup\n",
      "------------------------------------\n",
      "BE_actual_duration_[s] : 0.004\n",
      "BE_amplitude_[V] : 1\n",
      "BE_auto_smoothing : auto smoothing on\n",
      "BE_band_edge_smoothing_[s] : 4832.1\n",
      "BE_band_edge_trim : 0.094742\n",
      "BE_band_width_[Hz] : 200000\n",
      "BE_bins_per_band : 0\n",
      "BE_center_frequency_[Hz] : 1310000\n",
      "BE_desired_duration_[s] : 0.004\n",
      "BE_phase_content : chirp-sinc hybrid\n",
      "BE_phase_variation : 1\n",
      "BE_points_per_BE_wave : 0\n",
      "BE_repeats : 4\n",
      "FORC_V_high1_[V] : 1\n",
      "FORC_V_high2_[V] : 10\n",
      "FORC_V_low1_[V] : -1\n",
      "FORC_V_low2_[V] : -10\n",
      "FORC_num_of_FORC_cycles : 1\n",
      "FORC_num_of_FORC_repeats : 1\n",
      "File_MDAQ_version : MDAQ_VS_090915_01\n",
      "File_date_and_time : 18-Sep-2015 18:32:14\n",
      "File_file_name : SP128_NSO\n",
      "File_file_path : C:\\Users\\Asylum User\\Documents\\Users\\Agar\\SP128_NSO\\\n",
      "File_file_suffix : 99\n",
      "IO_AO_amplifier : 10\n",
      "IO_AO_range_[V] : +/- 10\n",
      "IO_Analog_Input_1 : +/- .1V, FFT\n",
      "IO_Analog_Input_2 : off\n",
      "IO_Analog_Input_3 : off\n",
      "IO_Analog_Input_4 : off\n",
      "IO_DAQ_platform : NI 6115\n",
      "IO_rate_[Hz] : 4000000\n",
      "VS_amplitude_[V] : 16\n",
      "VS_cycle_fraction : full\n",
      "VS_cycle_phase_shift : 0\n",
      "VS_measure_in_field_loops : in and out-of-field\n",
      "VS_mode : DC modulation mode\n",
      "VS_number_of_cycles : 2\n",
      "VS_offset_[V] : 0\n",
      "VS_read_voltage_[V] : 0\n",
      "VS_set_pulse_amplitude[V] : 0\n",
      "VS_set_pulse_duration[s] : 0.002\n",
      "VS_step_edge_smoothing_[s] : 0.001\n",
      "VS_steps_per_full_cycle : 96\n",
      "data_type : BEPSData\n",
      "grid_/single : grid\n",
      "grid_contact_set_point_[V] : 1\n",
      "grid_current_col : 1\n",
      "grid_current_row : 1\n",
      "grid_cycle_time_[s] : 10\n",
      "grid_measuring : 0\n",
      "grid_moving : 0\n",
      "grid_num_cols : 60\n",
      "grid_num_rows : 60\n",
      "grid_settle_time_[s] : 0.15\n",
      "grid_time_remaining_[h;m;s] : 10\n",
      "grid_total_time_[h;m;s] : 10\n",
      "grid_transit_set_point_[V] : 0.1\n",
      "grid_transit_time_[s] : 0.15\n",
      "num_bins : 165\n",
      "num_pix : 3600\n",
      "num_udvs_steps : 384\n"
     ]
    }
   ],
   "source": [
    "# instantiate the dataset object\n",
    "dataset = BE_Dataset(data_path, SHO_fit_func_LSQF=SHO_nn)\n",
    "\n",
    "# print the contents of the file\n",
    "dataset.print_be_tree()\n",
    "\n",
    "# Get the current date and time\n",
    "current_datetime = datetime.now()\n",
    "\n",
    "# Format the date and time in a 'pretty' format (e.g., YYYY-MM-DD_HH-MM-SS)\n",
    "formatted_datetime = current_datetime.strftime('%Y-%m-%d_%H-%M-%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type is <class 'dict'>\n",
      "Pytorch seed was set to 41\n",
      "Numpy seed was set to 41\n",
      "tensorflow seed was set to 41\n",
      "Working on combination: SHO_TRCG_noise_0_batch_size_500_seed_41\n",
      "Using GPU NVIDIA GeForce RTX 3090\n",
      "Saving to Trained Models/SHO Fitter//2024-09-12_18-31-42_nn_benchmarks_noise/\n",
      "Pytorch seed was set to 41\n",
      "Numpy seed was set to 41\n",
      "tensorflow seed was set to 41\n",
      "Adam\n",
      "epoch : 1/5, recon loss = 0.06054313\n",
      "--- 17.516742944717407 seconds ---\n",
      "Epoch 1, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 2/5, recon loss = 0.03451453\n",
      "--- 17.219754219055176 seconds ---\n",
      "Epoch 2, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 3/5, recon loss = 0.03421530\n",
      "--- 17.368999242782593 seconds ---\n",
      "Epoch 3, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 4/5, recon loss = 0.03368135\n",
      "--- 912.2405369281769 seconds ---\n",
      "Epoch 4, Learning Rate: 0.001\n",
      "The type is <class 'dict'>\n",
      "Pytorch seed was set to 43\n",
      "Numpy seed was set to 43\n",
      "tensorflow seed was set to 43\n",
      "Working on combination: SHO_TRCG_noise_0_batch_size_500_seed_43\n",
      "Using GPU NVIDIA GeForce RTX 3090\n",
      "Saving to Trained Models/SHO Fitter//2024-09-12_18-31-42_nn_benchmarks_noise/\n",
      "Pytorch seed was set to 43\n",
      "Numpy seed was set to 43\n",
      "tensorflow seed was set to 43\n",
      "Adam\n",
      "epoch : 1/5, recon loss = 0.05761567\n",
      "--- 16.95794916152954 seconds ---\n",
      "Epoch 1, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 2/5, recon loss = 0.03448168\n",
      "--- 17.370609760284424 seconds ---\n",
      "Epoch 2, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 3/5, recon loss = 0.03419863\n",
      "--- 17.49360990524292 seconds ---\n",
      "Epoch 3, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 4/5, recon loss = 0.03360792\n",
      "--- 974.6734941005707 seconds ---\n",
      "Epoch 4, Learning Rate: 0.001\n",
      "The type is <class 'dict'>\n",
      "Pytorch seed was set to 44\n",
      "Numpy seed was set to 44\n",
      "tensorflow seed was set to 44\n",
      "Working on combination: SHO_TRCG_noise_0_batch_size_500_seed_44\n",
      "Using GPU NVIDIA GeForce RTX 3090\n",
      "Saving to Trained Models/SHO Fitter//2024-09-12_18-31-42_nn_benchmarks_noise/\n",
      "Pytorch seed was set to 44\n",
      "Numpy seed was set to 44\n",
      "tensorflow seed was set to 44\n",
      "Adam\n",
      "epoch : 1/5, recon loss = 0.05873379\n",
      "--- 17.557775497436523 seconds ---\n",
      "Epoch 1, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 2/5, recon loss = 0.03483970\n",
      "--- 17.365057468414307 seconds ---\n",
      "Epoch 2, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 3/5, recon loss = 0.03440588\n",
      "--- 17.524878978729248 seconds ---\n",
      "Epoch 3, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 4/5, recon loss = 0.03370838\n",
      "--- 790.3839392662048 seconds ---\n",
      "Epoch 4, Learning Rate: 0.001\n",
      "The type is <class 'dict'>\n",
      "Pytorch seed was set to 45\n",
      "Numpy seed was set to 45\n",
      "tensorflow seed was set to 45\n",
      "Working on combination: SHO_TRCG_noise_0_batch_size_500_seed_45\n",
      "Using GPU NVIDIA GeForce RTX 3090\n",
      "Saving to Trained Models/SHO Fitter//2024-09-12_18-31-42_nn_benchmarks_noise/\n",
      "Pytorch seed was set to 45\n",
      "Numpy seed was set to 45\n",
      "tensorflow seed was set to 45\n",
      "Adam\n",
      "epoch : 1/5, recon loss = 0.07922767\n",
      "--- 17.241686820983887 seconds ---\n",
      "Epoch 1, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 2/5, recon loss = 0.03505122\n",
      "--- 17.324211359024048 seconds ---\n",
      "Epoch 2, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 3/5, recon loss = 0.03447882\n",
      "--- 17.253076553344727 seconds ---\n",
      "Epoch 3, Learning Rate: 0.001\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 23.68 GiB of which 1.81 MiB is free. Including non-PyTorch memory, this process has 23.68 GiB memory in use. Of the allocated memory 23.29 GiB is allocated by PyTorch, and 73.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m basepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mformatted_datetime\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbasepath_postfix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# # Usage example\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# system_info = SystemInfo()\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# cpu_info, gpu_info = system_info.get_system_info()\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# system_info.save_to_file(\"Trained Models/\" + basepath,\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#                          \"system_info.txt\", cpu_info, gpu_info)\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mbatch_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m               \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m               \u001b[49m\u001b[43mwrite_CSV\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBatch_Trainging_SpeedTest.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m               \u001b[49m\u001b[43mbasepath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbasepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m               \u001b[49m\u001b[43mearly_stopping_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_time\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/BEPiezo-Learn/src/belearn/nn/nn.py:18\u001b[0m, in \u001b[0;36mstatic_state_decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     17\u001b[0m     current_state \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_state\n\u001b[0;32m---> 18\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_attributes(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcurrent_state)\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/BEPiezo-Learn/src/belearn/nn/nn.py:179\u001b[0m, in \u001b[0;36mbatch_training\u001b[0;34m(dataset, optimizers, noise_list, batch_size, epochs, seed, write_CSV, basepath, early_stopping_loss, early_stopping_count, early_stopping_time, skip, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(model_, dataset, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    176\u001b[0m               model_basename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSHO_Fitter_original_data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# fits the model\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrite_CSV\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrite_CSV\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbasepath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbasepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m model, X_train, X_test, y_train, y_test\n\u001b[1;32m    196\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "File \u001b[0;32m~/AutoPhysLearn/src/autophyslearn/spectroscopic/nn.py:372\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, data_train, batch_size, epochs, loss_func, optimizer, seed, datatype, save_all, write_CSV, closure, basepath, early_stopping_loss, early_stopping_count, early_stopping_time, save_training_loss, i, **kwargs)\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m# Perform a Trust Region CG step\u001b[39;00m\n\u001b[0;32m--> 372\u001b[0m loss, radius, cnt_compute, cg_iter \u001b[38;5;241m=\u001b[39m \u001b[43mTRCG_OP\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    373\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m*\u001b[39m train_batch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    374\u001b[0m total_num \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m train_batch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/m3/lib/python3.11/site-packages/torch/optim/optimizer.py:484\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    480\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m             )\n\u001b[0;32m--> 484\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/m3/lib/python3.11/site-packages/torch/optim/optimizer.py:89\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     88\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 89\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     91\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/anaconda3/envs/m3/lib/python3.11/site-packages/m3util/ml/optimizers/TrustRegion.py:352\u001b[0m, in \u001b[0;36mTRCG.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    350\u001b[0m wInit \u001b[38;5;241m=\u001b[39m [w\u001b[38;5;241m.\u001b[39mclone() \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams]  \u001b[38;5;66;03m# Store the initial weights\u001b[39;00m\n\u001b[0;32m--> 352\u001b[0m lossInit, loss_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomputeGradientAndLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m NormG \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomputeNorm(loss_grad)\n\u001b[1;32m    355\u001b[0m cnt_compute \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/m3/lib/python3.11/site-packages/m3util/ml/optimizers/TrustRegion.py:283\u001b[0m, in \u001b[0;36mTRCG.computeGradientAndLoss\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    281\u001b[0m lossVal \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclosure_size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 283\u001b[0m     loss_grad \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_cache \u001b[38;5;241m=\u001b[39m loss_grad\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/m3/lib/python3.11/site-packages/torch/autograd/__init__.py:436\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    432\u001b[0m     result \u001b[38;5;241m=\u001b[39m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[1;32m    433\u001b[0m         grad_outputs_\n\u001b[1;32m    434\u001b[0m     )\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 436\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    447\u001b[0m         result[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor_like(inputs[i])\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs))\n\u001b[1;32m    449\u001b[0m     ):\n",
      "File \u001b[0;32m~/anaconda3/envs/m3/lib/python3.11/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 23.68 GiB of which 1.81 MiB is free. Including non-PyTorch memory, this process has 23.68 GiB memory in use. Of the allocated memory 23.29 GiB is allocated by PyTorch, and 73.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "basepath = f'{formatted_datetime}_{basepath_postfix}'\n",
    "\n",
    "# # Usage example\n",
    "# system_info = SystemInfo()\n",
    "# cpu_info, gpu_info = system_info.get_system_info()\n",
    "# system_info.save_to_file(\"Trained Models/\" + basepath,\n",
    "#                          \"system_info.txt\", cpu_info, gpu_info)\n",
    "\n",
    "batch_training(dataset, optimizers, noise_list, batch_size, epochs,\n",
    "               seed,\n",
    "               write_CSV=\"Batch_Trainging_SpeedTest.csv\",\n",
    "               basepath=basepath, \n",
    "               early_stopping_time=early_stopping_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# Generate all combinations\n",
    "combinations = list(itertools.product(\n",
    "    optimizers, noise_list, batch_size, epochs, seed))\n",
    "\n",
    "for i, training in enumerate(combinations):\n",
    "\n",
    "    optimizer_ = training[0]\n",
    "    noise_ = training[1]\n",
    "    seed_ = training[4]\n",
    "\n",
    "    print(i, optimizer_, noise_, seed_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m3learning-new",
   "language": "python",
   "name": "m3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
